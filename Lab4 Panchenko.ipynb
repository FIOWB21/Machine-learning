{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 4532039,
          "sourceType": "datasetVersion",
          "datasetId": 2579480
        }
      ],
      "dockerImageVersionId": 31011,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "notebook66473b4d06",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.utils import make_grid\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "# filter warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T18:08:28.689292Z",
          "iopub.execute_input": "2025-04-15T18:08:28.689545Z",
          "iopub.status.idle": "2025-04-15T18:08:41.096258Z",
          "shell.execute_reply.started": "2025-04-15T18:08:28.68952Z",
          "shell.execute_reply": "2025-04-15T18:08:41.095373Z"
        },
        "id": "lWqAj2c3xIeg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir ='/kaggle/input/cards-image-datasetclassification/train'\n",
        "val_dir ='/kaggle/input/cards-image-datasetclassification/valid'\n",
        "test_dir ='/kaggle/input/cards-image-datasetclassification/test'"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T18:08:41.098193Z",
          "iopub.execute_input": "2025-04-15T18:08:41.098781Z",
          "iopub.status.idle": "2025-04-15T18:08:41.102932Z",
          "shell.execute_reply.started": "2025-04-15T18:08:41.098753Z",
          "shell.execute_reply": "2025-04-15T18:08:41.102205Z"
        },
        "id": "hkyoGNjjxIeh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((150, 150)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T18:08:41.103621Z",
          "iopub.execute_input": "2025-04-15T18:08:41.103828Z",
          "iopub.status.idle": "2025-04-15T18:08:41.122059Z",
          "shell.execute_reply.started": "2025-04-15T18:08:41.103812Z",
          "shell.execute_reply": "2025-04-15T18:08:41.12138Z"
        },
        "id": "KKi0xFsIxIeh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
        "val_dataset = datasets.ImageFolder(val_dir, transform=transform)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T18:08:41.122796Z",
          "iopub.execute_input": "2025-04-15T18:08:41.123008Z",
          "iopub.status.idle": "2025-04-15T18:09:12.182733Z",
          "shell.execute_reply.started": "2025-04-15T18:08:41.122955Z",
          "shell.execute_reply": "2025-04-15T18:09:12.18194Z"
        },
        "id": "fnVAcsW2xIeh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T18:09:12.183604Z",
          "iopub.execute_input": "2025-04-15T18:09:12.183866Z",
          "iopub.status.idle": "2025-04-15T18:09:12.187872Z",
          "shell.execute_reply.started": "2025-04-15T18:09:12.183838Z",
          "shell.execute_reply": "2025-04-15T18:09:12.18731Z"
        },
        "id": "ZzxWDj5LxIeh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(images, labels, class_names):\n",
        "    images = images.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    images = std * images + mean\n",
        "    images = np.clip(images, 0, 1)\n",
        "    plt.imshow(images)\n",
        "    plt.title(\", \".join([class_names[l] for l in labels]))\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T18:09:12.188552Z",
          "iopub.execute_input": "2025-04-15T18:09:12.18882Z",
          "iopub.status.idle": "2025-04-15T18:09:12.205131Z",
          "shell.execute_reply.started": "2025-04-15T18:09:12.188794Z",
          "shell.execute_reply": "2025-04-15T18:09:12.204299Z"
        },
        "id": "tffnwFBrxIei"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_loader.dataset.classes\n",
        "class_names"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T18:09:12.207539Z",
          "iopub.execute_input": "2025-04-15T18:09:12.207733Z",
          "iopub.status.idle": "2025-04-15T18:09:12.226416Z",
          "shell.execute_reply.started": "2025-04-15T18:09:12.207718Z",
          "shell.execute_reply": "2025-04-15T18:09:12.225472Z"
        },
        "id": "Pn2TdYsbxIei"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "imshow(make_grid(images[:10], nrow=5), labels[:10], class_names)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T18:09:12.227187Z",
          "iopub.execute_input": "2025-04-15T18:09:12.227497Z"
        },
        "id": "p6mJekTVxIei"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Кількість класів: {len(train_dataset.classes)}\")\n",
        "print(f\"Класи: {train_dataset.classes}\")\n",
        "print(f\"Розмір тренувального набору: {len(train_dataset)}\")\n",
        "print(f\"Розмір валідаційного набору: {len(val_dataset)}\")\n",
        "print(f\"Розмір тестового набору: {len(test_dataset)}\")\n",
        "\n",
        "class_counts = {class_name: 0 for class_name in train_dataset.classes}\n",
        "for _, label in train_dataset.samples:\n",
        "    class_counts[train_dataset.classes[label]] += 1\n",
        "\n",
        "print(\"\\nРозподіл класів у тренувальному наборі:\")\n",
        "for class_name, count in class_counts.items():\n",
        "    print(f\"{class_name}: {count}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "zC6jyRCZxIei"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=36):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        # Обчислити розмір вхідних даних для повнозв'язного шару\n",
        "        self._initialize_fc_layer()\n",
        "\n",
        "        self.fc1 = nn.Linear(self.fc1_in_features, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _initialize_fc_layer(self):\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros(1, 3, 150, 150)\n",
        "            dummy_output = self._forward_conv_layers(dummy_input)\n",
        "            self.fc1_in_features = dummy_output.numel()\n",
        "\n",
        "    def _forward_conv_layers(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self._forward_conv_layers(x)\n",
        "        x = x.view(-1, self.fc1_in_features)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "trusted": true,
        "id": "tNmuttd7xIej"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleCNN(num_classes=53)\n",
        "\n",
        "# Перенесення моделі на GPU, якщо доступно\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.idle": "2025-04-15T18:09:13.93794Z",
          "shell.execute_reply.started": "2025-04-15T18:09:13.402987Z",
          "shell.execute_reply": "2025-04-15T18:09:13.937393Z"
        },
        "id": "2Kkw11xSxIej"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 15\n",
        "best_val_loss = float('inf')\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T18:09:13.93862Z",
          "iopub.execute_input": "2025-04-15T18:09:13.938865Z",
          "iopub.status.idle": "2025-04-15T18:09:13.943569Z",
          "shell.execute_reply.started": "2025-04-15T18:09:13.938844Z",
          "shell.execute_reply": "2025-04-15T18:09:13.94289Z"
        },
        "id": "JaW3eBugxIej"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in tqdm(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_accuracy = correct / total\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Валідація\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    val_accuracy = correct / total\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "    print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
        "    print(f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'best_model_1.pth')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T18:09:13.944161Z",
          "iopub.execute_input": "2025-04-15T18:09:13.94442Z",
          "iopub.status.idle": "2025-04-15T18:16:08.320195Z",
          "shell.execute_reply.started": "2025-04-15T18:09:13.944403Z",
          "shell.execute_reply": "2025-04-15T18:16:08.319575Z"
        },
        "id": "mc5VrOS4xIej"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_predictions(model, dataloader, class_names, num_images=5):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure(figsize=(15, 10))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size(0)):\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    plt.tight_layout()\n",
        "                    plt.show()\n",
        "                    return\n",
        "\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2 + 1, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title(f'Predicted: {class_names[preds[j]]}\\nTrue: {class_names[labels[j]]}')\n",
        "\n",
        "                # Денормалізація зображення для відображення\n",
        "                inv_normalize = transforms.Normalize(\n",
        "                    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
        "                    std=[1/0.229, 1/0.224, 1/0.225]\n",
        "                )\n",
        "                inp = inv_normalize(inputs.cpu()[j]).numpy().transpose((1, 2, 0))\n",
        "                inp = np.clip(inp, 0, 1)\n",
        "\n",
        "                plt.imshow(inp)\n",
        "\n",
        "    model.train(mode=was_training)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T18:16:08.320993Z",
          "iopub.execute_input": "2025-04-15T18:16:08.321267Z",
          "iopub.status.idle": "2025-04-15T18:16:08.328157Z",
          "shell.execute_reply.started": "2025-04-15T18:16:08.321243Z",
          "shell.execute_reply": "2025-04-15T18:16:08.327385Z"
        },
        "id": "Rpyedcs8xIej"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_metrics(train_losses, train_accuracies, val_losses, val_accuracies):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, 'b-', label='Training Loss')\n",
        "    plt.plot(epochs, val_losses, 'r-', label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_accuracies, 'b-', label='Training Accuracy')\n",
        "    plt.plot(epochs, val_accuracies, 'r-', label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T18:16:08.328998Z",
          "iopub.execute_input": "2025-04-15T18:16:08.329457Z",
          "iopub.status.idle": "2025-04-15T18:16:08.35401Z",
          "shell.execute_reply.started": "2025-04-15T18:16:08.329441Z",
          "shell.execute_reply": "2025-04-15T18:16:08.353518Z"
        },
        "id": "ZEBps-PxxIej"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('best_model_1.pth'))\n",
        "model.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T18:16:08.354599Z",
          "iopub.execute_input": "2025-04-15T18:16:08.354845Z",
          "iopub.status.idle": "2025-04-15T18:16:10.923229Z",
          "shell.execute_reply.started": "2025-04-15T18:16:08.354825Z",
          "shell.execute_reply": "2025-04-15T18:16:10.922667Z"
        },
        "id": "Dsk_O3OjxIek"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_dataset.classes\n",
        "\n",
        "test_accuracy = correct / total\n",
        "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T18:16:10.923922Z",
          "iopub.execute_input": "2025-04-15T18:16:10.924113Z",
          "iopub.status.idle": "2025-04-15T18:16:14.913119Z",
          "shell.execute_reply.started": "2025-04-15T18:16:10.924098Z",
          "shell.execute_reply": "2025-04-15T18:16:14.912394Z"
        },
        "id": "XSGR6uLSxIek"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_metrics(train_losses, train_accuracies, val_losses, val_accuracies)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T18:16:14.913887Z",
          "iopub.execute_input": "2025-04-15T18:16:14.914105Z",
          "iopub.status.idle": "2025-04-15T18:16:15.274878Z",
          "shell.execute_reply.started": "2025-04-15T18:16:14.914089Z",
          "shell.execute_reply": "2025-04-15T18:16:15.274243Z"
        },
        "id": "VK2dwpWdxIek"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_predictions(model, test_loader, train_dataset.classes, 15)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T18:16:15.275666Z",
          "iopub.execute_input": "2025-04-15T18:16:15.275988Z",
          "iopub.status.idle": "2025-04-15T18:16:16.036161Z",
          "shell.execute_reply.started": "2025-04-15T18:16:15.275969Z",
          "shell.execute_reply": "2025-04-15T18:16:16.035475Z"
        },
        "id": "GW7s6dWSxIek"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "num_ftrs = model.classifier[6].in_features  # Останній шар у classifier\n",
        "model.classifier[6] = nn.Linear(num_ftrs, 53)  # 53 класів у наборі даних\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T18:16:16.036908Z",
          "iopub.execute_input": "2025-04-15T18:16:16.03714Z",
          "iopub.status.idle": "2025-04-15T18:16:20.459498Z",
          "shell.execute_reply.started": "2025-04-15T18:16:16.037121Z",
          "shell.execute_reply": "2025-04-15T18:16:20.458871Z"
        },
        "id": "nvm77y5jxIek"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.classifier[6].parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 30\n",
        "best_val_loss = float('inf')\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T18:16:20.460198Z",
          "iopub.execute_input": "2025-04-15T18:16:20.460427Z",
          "iopub.status.idle": "2025-04-15T18:16:20.465385Z",
          "shell.execute_reply.started": "2025-04-15T18:16:20.460411Z",
          "shell.execute_reply": "2025-04-15T18:16:20.464746Z"
        },
        "id": "wBMKpe0_xIek"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in tqdm(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_accuracy = correct / total\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    val_accuracy = correct / total\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "    print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
        "    print(f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'best_model_2.pth')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T18:16:20.468259Z",
          "iopub.execute_input": "2025-04-15T18:16:20.468516Z",
          "iopub.status.idle": "2025-04-15T18:31:02.33865Z",
          "shell.execute_reply.started": "2025-04-15T18:16:20.468499Z",
          "shell.execute_reply": "2025-04-15T18:31:02.337983Z"
        },
        "id": "pbBeIU5XxIek"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Висновок:\n",
        "У цій лабораторній роботі ми попрацювали з даними про гральні карти та навчили модель класифікувати їх за допомогою методу опорних векторів (SVM). Для зручності та візуалізації ми обрали лише дві числові ознаки — це дало можливість побачити, як модель будує межу між класами в просторі ознак. Навчання моделі пройшло успішно: вона змогла визначити гіперплощину, яка ефективно розділяє різні типи карт."
      ],
      "metadata": {
        "id": "rSdkSG8RxIek"
      }
    }
  ]
}